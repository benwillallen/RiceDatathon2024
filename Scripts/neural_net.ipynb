{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Using Neural Networks to Predict Oil Peak Rate\n",
        "\n",
        "### Loading and preparing the data\n",
        "For a neural network, the data is best normalized using mean / standard deviation normalization. However, for the positional data, to avoid the warping of space, they both have the same standard deviation for the sake of normalization."
      ],
      "metadata": {
        "id": "XQZ2_MJDCzkI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "# Load the training and testing data\n",
        "df = pd.read_csv('/content/drive/MyDrive/Datathon 2024/Data/preprocessed_training.csv')\n",
        "\n",
        "# Gets the testing and training indices from the csv in the drive, shared with XGBoost\n",
        "training_indices = np.array(pd.read_csv('/content/drive/MyDrive/Datathon 2024/Data/StandardSplit.csv')[\"train_test_split\"])\n",
        "training_indices -= 1\n",
        "\n",
        "# Dropping columns that are either redundant, very hard to represent, or irrelevant\n",
        "df.drop([\"standardized_operator_name\", \"proppant_to_frac_fluid_ratio\", \"total_proppant\", \"total_fluid\", \"horizontal_dist_x\", \"horizontal_dist_y\"], inplace=True, axis=1)\n",
        "\n",
        "# Saving the target variable standard deviation and mean before normalization to convert the data back later\n",
        "oil_std = df[\"OilPeakRate\"].std()\n",
        "oil_mean = df[\"OilPeakRate\"].mean()\n",
        "\n",
        "# Creating a standard deviation value for both the x and y coordinates as to not cause warping during normalization\n",
        "coord_std = (df[\"surface_x\"].std() + df[\"surface_y\"].std()) / 2\n",
        "\n",
        "# Mean standard deviation normalization function\n",
        "def mean_std_normalization(column):\n",
        "    mean = column.mean()\n",
        "    std_dev = column.std()\n",
        "    if column.name not in (\"surface_x\", \"surface_y\"):\n",
        "      normalized_column = (column - mean) / std_dev\n",
        "    else:\n",
        "      normalized_column = (column - mean) / coord_std\n",
        "    return normalized_column\n",
        "\n",
        "# Apply mean standard deviation normalization to each column\n",
        "df = df.apply(mean_std_normalization)\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        },
        "id": "qDJaVyFXRIJu",
        "outputId": "ffa978a8-e958-4246-b5fe-167745d09784"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   OilPeakRate  surface_x  surface_y  gross_perforated_length  \\\n",
              "0    -1.112048   1.473690  -1.489933                -1.004684   \n",
              "1    -1.027789   1.460921  -1.511878                -1.334935   \n",
              "2    -1.342079   1.459185  -1.487842                -1.069325   \n",
              "3    -0.616681   1.473989  -1.533268                -1.105790   \n",
              "4    -0.754609   1.455320  -1.549551                -1.068911   \n",
              "\n",
              "   true_vertical_depth  proppant_intensity  frac_fluid_intensity  \\\n",
              "0            -0.064585           -1.685204             -1.561580   \n",
              "1            -0.110165           -1.376399             -1.323028   \n",
              "2            -0.016885           -0.628038             -0.481106   \n",
              "3            -0.105925           -1.505428             -1.522248   \n",
              "4            -0.090555           -1.488616             -1.367058   \n",
              "\n",
              "   bin_lateral_length  frac_seasoning  horizontal_dist  ...  Undefined  \\\n",
              "0           -0.779946       -0.463977        -0.969622  ...  -0.233983   \n",
              "1           -0.779946       -0.159840        -1.267642  ...  -0.233983   \n",
              "2           -0.779946        0.509263        -1.082754  ...  -0.233983   \n",
              "3           -0.779946       -0.366653        -0.998418  ...  -0.233983   \n",
              "4           -0.779946       -0.354488        -0.976812  ...  -0.233983   \n",
              "\n",
              "   Inner Well  Outer Well  Batch-Concurrent Frac  Batch-Sequential Frac  \\\n",
              "0   -0.571134   -0.668564              -0.560283              -0.412411   \n",
              "1   -0.571134    1.495665              -0.560283              -0.412411   \n",
              "2   -0.571134   -0.668564              -0.560283              -0.412411   \n",
              "3   -0.571134   -0.668564              -0.560283              -0.412411   \n",
              "4   -0.571134    1.495665              -0.560283              -0.412411   \n",
              "\n",
              "   Non-Batch Frac  Infill Child Well  Sibling Well  Standalone Well   Unknown  \n",
              "0       -0.757834          -0.485485     -0.756733         1.171525 -0.155543  \n",
              "1       -0.757834           2.059687     -0.756733        -0.853544 -0.155543  \n",
              "2        1.319483          -0.485485     -0.756733         1.171525 -0.155543  \n",
              "3       -0.757834          -0.485485     -0.756733         1.171525 -0.155543  \n",
              "4       -0.757834           2.059687     -0.756733        -0.853544 -0.155543  \n",
              "\n",
              "[5 rows x 25 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2c931938-efa0-4c8d-8d4f-fa827f57f9b5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OilPeakRate</th>\n",
              "      <th>surface_x</th>\n",
              "      <th>surface_y</th>\n",
              "      <th>gross_perforated_length</th>\n",
              "      <th>true_vertical_depth</th>\n",
              "      <th>proppant_intensity</th>\n",
              "      <th>frac_fluid_intensity</th>\n",
              "      <th>bin_lateral_length</th>\n",
              "      <th>frac_seasoning</th>\n",
              "      <th>horizontal_dist</th>\n",
              "      <th>...</th>\n",
              "      <th>Undefined</th>\n",
              "      <th>Inner Well</th>\n",
              "      <th>Outer Well</th>\n",
              "      <th>Batch-Concurrent Frac</th>\n",
              "      <th>Batch-Sequential Frac</th>\n",
              "      <th>Non-Batch Frac</th>\n",
              "      <th>Infill Child Well</th>\n",
              "      <th>Sibling Well</th>\n",
              "      <th>Standalone Well</th>\n",
              "      <th>Unknown</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1.112048</td>\n",
              "      <td>1.473690</td>\n",
              "      <td>-1.489933</td>\n",
              "      <td>-1.004684</td>\n",
              "      <td>-0.064585</td>\n",
              "      <td>-1.685204</td>\n",
              "      <td>-1.561580</td>\n",
              "      <td>-0.779946</td>\n",
              "      <td>-0.463977</td>\n",
              "      <td>-0.969622</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.233983</td>\n",
              "      <td>-0.571134</td>\n",
              "      <td>-0.668564</td>\n",
              "      <td>-0.560283</td>\n",
              "      <td>-0.412411</td>\n",
              "      <td>-0.757834</td>\n",
              "      <td>-0.485485</td>\n",
              "      <td>-0.756733</td>\n",
              "      <td>1.171525</td>\n",
              "      <td>-0.155543</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1.027789</td>\n",
              "      <td>1.460921</td>\n",
              "      <td>-1.511878</td>\n",
              "      <td>-1.334935</td>\n",
              "      <td>-0.110165</td>\n",
              "      <td>-1.376399</td>\n",
              "      <td>-1.323028</td>\n",
              "      <td>-0.779946</td>\n",
              "      <td>-0.159840</td>\n",
              "      <td>-1.267642</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.233983</td>\n",
              "      <td>-0.571134</td>\n",
              "      <td>1.495665</td>\n",
              "      <td>-0.560283</td>\n",
              "      <td>-0.412411</td>\n",
              "      <td>-0.757834</td>\n",
              "      <td>2.059687</td>\n",
              "      <td>-0.756733</td>\n",
              "      <td>-0.853544</td>\n",
              "      <td>-0.155543</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1.342079</td>\n",
              "      <td>1.459185</td>\n",
              "      <td>-1.487842</td>\n",
              "      <td>-1.069325</td>\n",
              "      <td>-0.016885</td>\n",
              "      <td>-0.628038</td>\n",
              "      <td>-0.481106</td>\n",
              "      <td>-0.779946</td>\n",
              "      <td>0.509263</td>\n",
              "      <td>-1.082754</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.233983</td>\n",
              "      <td>-0.571134</td>\n",
              "      <td>-0.668564</td>\n",
              "      <td>-0.560283</td>\n",
              "      <td>-0.412411</td>\n",
              "      <td>1.319483</td>\n",
              "      <td>-0.485485</td>\n",
              "      <td>-0.756733</td>\n",
              "      <td>1.171525</td>\n",
              "      <td>-0.155543</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.616681</td>\n",
              "      <td>1.473989</td>\n",
              "      <td>-1.533268</td>\n",
              "      <td>-1.105790</td>\n",
              "      <td>-0.105925</td>\n",
              "      <td>-1.505428</td>\n",
              "      <td>-1.522248</td>\n",
              "      <td>-0.779946</td>\n",
              "      <td>-0.366653</td>\n",
              "      <td>-0.998418</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.233983</td>\n",
              "      <td>-0.571134</td>\n",
              "      <td>-0.668564</td>\n",
              "      <td>-0.560283</td>\n",
              "      <td>-0.412411</td>\n",
              "      <td>-0.757834</td>\n",
              "      <td>-0.485485</td>\n",
              "      <td>-0.756733</td>\n",
              "      <td>1.171525</td>\n",
              "      <td>-0.155543</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.754609</td>\n",
              "      <td>1.455320</td>\n",
              "      <td>-1.549551</td>\n",
              "      <td>-1.068911</td>\n",
              "      <td>-0.090555</td>\n",
              "      <td>-1.488616</td>\n",
              "      <td>-1.367058</td>\n",
              "      <td>-0.779946</td>\n",
              "      <td>-0.354488</td>\n",
              "      <td>-0.976812</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.233983</td>\n",
              "      <td>-0.571134</td>\n",
              "      <td>1.495665</td>\n",
              "      <td>-0.560283</td>\n",
              "      <td>-0.412411</td>\n",
              "      <td>-0.757834</td>\n",
              "      <td>2.059687</td>\n",
              "      <td>-0.756733</td>\n",
              "      <td>-0.853544</td>\n",
              "      <td>-0.155543</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 25 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2c931938-efa0-4c8d-8d4f-fa827f57f9b5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2c931938-efa0-4c8d-8d4f-fa827f57f9b5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2c931938-efa0-4c8d-8d4f-fa827f57f9b5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3b3fed17-1730-43a6-ad8a-99e0bc5b46b2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3b3fed17-1730-43a6-ad8a-99e0bc5b46b2')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3b3fed17-1730-43a6-ad8a-99e0bc5b46b2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adding the Gaussian Approximations\n",
        "An approximation of the oil peak rate value can be acquired by looking at the surrounding points. For each training and testing point, a Gaussian probability density function (PDF) is created. Then, the surrounding training wells will have their peak oil values multiplied by the PDF's value at the well's location. All of these products are summed and divided by the sum of all PDF values used. This is the approximation.\n",
        "\n",
        "It is important to note that data leaks are avoided because only TRAINING wells are searched for in the surrounding area."
      ],
      "metadata": {
        "id": "lavCYSA8DNby"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.spatial import cKDTree\n",
        "from scipy.stats import norm\n",
        "\n",
        "QUERY_RADIUS = 0.3 # Radius (in xy-coordinate standard deviations defined further above) at which the estimator will query for training points\n",
        "STDEV = 0.01 # The standard deviation of the Gaussian distribution itself\n",
        "\n",
        "def add_gaussian_approximations(train_tensor, train_y, test_tensor):\n",
        "  \"\"\"\n",
        "  Returns the updated training tensors with a new column including the\n",
        "  Gaussian estimates for each point\n",
        "  \"\"\"\n",
        "  train_tensor, test_tensor, train_y = train_tensor.numpy(), test_tensor.numpy(), train_y.numpy()\n",
        "\n",
        "  # Getting the xy points\n",
        "  points = np.array([train_tensor[:,0], train_tensor[:,1]]).transpose()\n",
        "\n",
        "  # Forming it into a KD tree for fast querying in the long run, very easy to search for nearby points\n",
        "  kdtree = cKDTree(points)\n",
        "\n",
        "  # Creating a lookup table for the oil values for each point\n",
        "  data_dict = {}\n",
        "  for i, row in enumerate(train_tensor):\n",
        "    if row[0] not in data_dict:\n",
        "      data_dict[row[0]] = {}\n",
        "    data_dict[row[0]][row[1]] = train_y[i,0]\n",
        "\n",
        "  def gaussian_pdf(x, mean, std_dev):\n",
        "    \"\"\"\n",
        "    Returns the value of the Gaussian PDF at x with a distribution with a given mean and standard deviation\n",
        "    \"\"\"\n",
        "    exponent = -0.5 * ((x - mean) / std_dev) ** 2\n",
        "    pdf = (1 / (std_dev * np.sqrt(2 * np.pi))) * np.exp(exponent)\n",
        "    return pdf\n",
        "\n",
        "  def get_gaussian(point):\n",
        "    \"\"\"\n",
        "    Gets the Gaussian estimate for a single point using the Gaussian PDF\n",
        "    \"\"\"\n",
        "    point = np.array(point)\n",
        "\n",
        "    # Queries for surrounding points\n",
        "    other_points = points[kdtree.query_ball_point(point, QUERY_RADIUS)]\n",
        "\n",
        "    if len(other_points) < 10:\n",
        "      # If there is nothing in the query neighborhood, just use the entire training set. Should be rare so not much of a slowdown expected.\n",
        "      other_points = points\n",
        "\n",
        "    # Gets the list of oil values for each point\n",
        "    vals = np.array([data_dict[pt[0]][pt[1]] for pt in other_points])\n",
        "\n",
        "    # Calculates the Gaussian PDF value based on the distance from the point for each nearby training well\n",
        "    distances = np.linalg.norm(other_points - point, axis=1)\n",
        "    gaussians = gaussian_pdf(distances, 0, STDEV)\n",
        "    gaussians, vals = gaussians[distances != 0], vals[distances != 0]\n",
        "\n",
        "    # Adds the products and normalizes for the final estimate\n",
        "    result = sum(vals * gaussians) / sum(gaussians)\n",
        "    return result\n",
        "\n",
        "  # Handles nan issues, adds the Gaussian column to the train and test data sets.\n",
        "  train_results = torch.tensor(np.nan_to_num(np.array([get_gaussian([row[0], row[1]]) for row in torch.tensor(train_tensor)]).reshape(-1,1), nan=0))\n",
        "  train_results = torch.cat((torch.tensor(train_tensor), train_results), dim=1)\n",
        "  test_results = torch.tensor(np.nan_to_num(np.array([get_gaussian([row[0], row[1]]) for row in torch.tensor(test_tensor)]).reshape(-1,1), nan=0))\n",
        "  test_results = torch.cat((torch.tensor(test_tensor), test_results), dim=1)\n",
        "  return train_results, test_results"
      ],
      "metadata": {
        "id": "G7NHmJx2qUJo"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that the functions have been defined, we can actually create our test and train variables"
      ],
      "metadata": {
        "id": "8d1jHIcIGnCa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "shYuDBUQQk0l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2bbe21a-f1c6-4485-85c1-ec524cabca32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-ac1cf4c84714>:57: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  result = sum(vals * gaussians) / sum(gaussians)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Creates the X and y data sets, where the OilPeakRate is the target variable\n",
        "X = df[df.drop([\"OilPeakRate\"], axis=1).columns]\n",
        "y = df[\"OilPeakRate\"]\n",
        "\n",
        "# Converts them into tensors to be used in the neural network\n",
        "X_tensor = torch.tensor(X.values, dtype=torch.float32)\n",
        "y_tensor = torch.tensor(y.values, dtype=torch.float32).view(-1, 1)\n",
        "\n",
        "# Splits into training and testing data based on the indices specified in the csv file at the top of the code\n",
        "train_indices = np.setdiff1d(np.arange(len(df)), training_indices)\n",
        "X_test, X_train = X_tensor[train_indices], X_tensor[training_indices]\n",
        "y_test, y_train = y_tensor[train_indices], y_tensor[training_indices]\n",
        "\n",
        "# Adds the Gaussian approximations to the X data\n",
        "X_train, X_test = add_gaussian_approximations(X_train, y_train, X_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Validate that there is a correlation between the ground truth y data and the Gaussian estimation ( > 0.6 is amazing compared to other data points alone)\n",
        "np.corrcoef(X_test[:,-1].numpy().flatten(), y_test.numpy().flatten())[0,1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N98eTURGFl1A",
        "outputId": "74a4f6d8-1b1a-4f6d-b211-2a138691bd09"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6598116659699832"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Neural Network Setup\n",
        "The data is split into three categories:\n",
        "*   Well info: categorical variables that describe the type and construction of the well\n",
        "*   Location: the xy coordinates of the well\n",
        "*   Structure: the length or amount of the important parts of the well\n",
        "\n",
        "Then it is brought through the following layers\n",
        "*   Dense layer for each category\n",
        "*   Concatenating the results\n",
        "*   A sigmoid activation layer to introduce non-linearity\n",
        "*   A dense layer\n",
        "*   A ReLU activation layer\n",
        "*   A dense layer\n",
        "\n",
        "This allows for each type of data to be encoded first with other pieces of data that are likely relevant to it before being concatenated and fully integrated with a larger dense layer.\n",
        "\n"
      ],
      "metadata": {
        "id": "5jxHPLFVHRwa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into three categories\n",
        "well_info_train, well_info_test = X_train[:,-15:], X_test[:,-15:]\n",
        "location_train, location_test = X_train[:,:2], X_test[:,:2]\n",
        "structure_train, structure_test = X_train[:,2:-15], X_test[:,2:-15]"
      ],
      "metadata": {
        "id": "55yRmSuKqIZX"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "# Define the neural network model\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self, well_info_size, location_size, structure_size):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.f1 = nn.Linear(well_info_size, 3) # Each category has a number of output channels (this has been experimented with)\n",
        "        self.f2 = nn.Linear(location_size, 6)\n",
        "        self.f3 = nn.Linear(structure_size, 7)\n",
        "        self.relu = nn.Sigmoid()\n",
        "        self.fc2 = nn.Linear(16, 32) # Each dense layer can increase or decrease in dimension. This one goes from 16 to 32\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.fc3 = nn.Linear(32, 1) # This dense layer creates the output variable we are trying to predict.\n",
        "\n",
        "    def forward(self, well_info_x, location_x, structure_x):\n",
        "        x1 = self.f1(well_info_x)\n",
        "        x2 = self.f2(location_x)\n",
        "        x3 = self.f3(structure_x)\n",
        "        x = self.relu(torch.cat((x1, x2, x3), dim=1)) # This is where the concatenation of the category outputs from their small dense layers happen\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "9p8vbdujVJyi"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Neural Network Training\n",
        "This is trained with...\n",
        "*   6000 epochs\n",
        "*   Optimizer: Stochastic Gradient Descent (SGD)\n",
        "*   Learning Rate: 0.05\n",
        "*   Momentum: .001\n",
        "\n"
      ],
      "metadata": {
        "id": "cX8HKrP3IYTT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "X_train, X_test = X_train.double(), X_test.double()\n",
        "y_train, y_test = y_train.double(), y_test.double()\n",
        "\n",
        "# Initialize the model\n",
        "well_info_size, location_size, structure_size = well_info_train.shape[1], location_train.shape[1], structure_train.shape[1]\n",
        "model = NeuralNetwork(well_info_size, location_size, structure_size).double()\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.05, momentum=1e-3)\n"
      ],
      "metadata": {
        "id": "y_NoGPnOVgCi"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model\n",
        "num_epochs = 6000\n",
        "for epoch in range(num_epochs):\n",
        "    # Forward pass\n",
        "    outputs = model(well_info_train, location_train, structure_train)\n",
        "    loss = criterion(outputs, y_train)\n",
        "\n",
        "    # Backward and optimize\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch+1) % 300 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
        "        with torch.no_grad():\n",
        "          test_outputs = model(well_info_test, location_test, structure_test)\n",
        "          test_loss = criterion(test_outputs, y_test)\n",
        "          print(f'Test Loss: {test_loss.item():.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlIWn6nhI2Wv",
        "outputId": "adf42235-358c-49ad-d6f5-d6313dc432e0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [300/6000], Loss: 0.5519\n",
            "Test Loss: 0.5193\n",
            "Epoch [600/6000], Loss: 0.4749\n",
            "Test Loss: 0.4458\n",
            "Epoch [900/6000], Loss: 0.4633\n",
            "Test Loss: 0.4356\n",
            "Epoch [1200/6000], Loss: 0.4594\n",
            "Test Loss: 0.4319\n",
            "Epoch [1500/6000], Loss: 0.4566\n",
            "Test Loss: 0.4292\n",
            "Epoch [1800/6000], Loss: 0.4543\n",
            "Test Loss: 0.4267\n",
            "Epoch [2100/6000], Loss: 0.4522\n",
            "Test Loss: 0.4244\n",
            "Epoch [2400/6000], Loss: 0.4501\n",
            "Test Loss: 0.4225\n",
            "Epoch [2700/6000], Loss: 0.4483\n",
            "Test Loss: 0.4209\n",
            "Epoch [3000/6000], Loss: 0.4468\n",
            "Test Loss: 0.4196\n",
            "Epoch [3300/6000], Loss: 0.4453\n",
            "Test Loss: 0.4185\n",
            "Epoch [3600/6000], Loss: 0.4441\n",
            "Test Loss: 0.4177\n",
            "Epoch [3900/6000], Loss: 0.4429\n",
            "Test Loss: 0.4170\n",
            "Epoch [4200/6000], Loss: 0.4419\n",
            "Test Loss: 0.4165\n",
            "Epoch [4500/6000], Loss: 0.4411\n",
            "Test Loss: 0.4161\n",
            "Epoch [4800/6000], Loss: 0.4403\n",
            "Test Loss: 0.4156\n",
            "Epoch [5100/6000], Loss: 0.4396\n",
            "Test Loss: 0.4153\n",
            "Epoch [5400/6000], Loss: 0.4390\n",
            "Test Loss: 0.4150\n",
            "Epoch [5700/6000], Loss: 0.4388\n",
            "Test Loss: 0.4149\n",
            "Epoch [6000/6000], Loss: 0.4391\n",
            "Test Loss: 0.4154\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2jh-KC9LDBB",
        "outputId": "071e4e2f-2622-4e22-be8e-b84c5a10694c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NeuralNetwork(\n",
              "  (f1): Linear(in_features=15, out_features=3, bias=True)\n",
              "  (f2): Linear(in_features=2, out_features=6, bias=True)\n",
              "  (f3): Linear(in_features=8, out_features=7, bias=True)\n",
              "  (relu): Sigmoid()\n",
              "  (fc2): Linear(in_features=16, out_features=32, bias=True)\n",
              "  (relu2): ReLU()\n",
              "  (fc3): Linear(in_features=32, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reviewing the testing data predictions and converting to a CSV"
      ],
      "metadata": {
        "id": "IMhLHtoEJx0E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Displays the RMSE\n",
        "(np.mean(((model(well_info_test, location_test, structure_test).detach().numpy() - y_test.detach().numpy()) * oil_std) ** 2) ** (1/2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7R0cYU1VOOt3",
        "outputId": "349229d5-2261-46e3-f71d-21d7f463c21e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100.40882511548143"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reconstructs the real oil time data and converts it to a csv file to be used with XGBoost\n",
        "preds = model(well_info_test, location_test, structure_test).detach().numpy().transpose()[0] * oil_std + oil_mean\n",
        "preds = pd.Series(preds)\n",
        "preds.name = \"predictions\"\n",
        "preds.to_csv(\"/content/drive/MyDrive/Datathon 2024/Data/neural_network_prediction.csv\", index=False)"
      ],
      "metadata": {
        "id": "qGlxXg6FOv9J"
      },
      "execution_count": 11,
      "outputs": []
    }
  ]
}